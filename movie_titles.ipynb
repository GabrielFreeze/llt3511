{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd37655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:00.454209Z",
     "start_time": "2022-11-21T23:50:00.445309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-family: JetBrains Mono;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-family: JetBrains Mono;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c304f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:02.167484Z",
     "start_time": "2022-11-21T23:50:00.455149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suggested imports. Do not use import any modules that are not in the requirements.txt file on the VLE.\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98e8ff",
   "metadata": {},
   "source": [
    "# Movie titles assignment\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "* [Data filtering and splitting (10%)](#Data-filtering-and-splitting-(10%))\n",
    "* [Title classification (25%)](#Title-classification-(25%))\n",
    "* [Title generation (25%)](#Title-generation-(25%))\n",
    "* [Language models as classifiers (30%)](#Language-models-as-classifiers-(30%))\n",
    "* [Conclusion (10%)](#Conclusion-(10%))\n",
    "\n",
    "Information:\n",
    "\n",
    "This assignment is 100% of your assessment.\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5373",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A big shot Hollywood producer is looking for a way to automatically generate new movie titles for future movies and you have been employed to do this (in exchange for millions of dollars!).\n",
    "A data set of movie details has already been collected from IMDb for you and your task is to create the model and the algorithms necessary to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2f45",
   "metadata": {},
   "source": [
    "## Data filtering and splitting (10%)\n",
    "\n",
    "Start by downloading the CSV file `filmtv_movies - ENG.csv` from [this kaggle data set](https://www.kaggle.com/datasets/stefanoleone992/filmtv-movies-dataset).\n",
    "\n",
    "The CSV file needs to be filtered as the producer is only interested in certain types of movie titles.\n",
    "Load the file and filter it so that only movies with the following criteria are kept:\n",
    "\n",
    "* The country needs to be `United States` (and no other country should be mentioned).\n",
    "* The genre should be `Action`, `Horror`, `Fantasy`, `Western`, and `Adventure`.\n",
    "* The title should not have more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751ea71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:02.500478Z",
     "start_time": "2022-11-21T23:50:02.168483Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2a2e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:02.879495Z",
     "start_time": "2022-11-21T23:50:02.502480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18149</th>\n",
       "      <td>geronimo</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34982</th>\n",
       "      <td>a-x-l</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>conquest of space</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>white feather</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29160</th>\n",
       "      <td>the signal</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35426</th>\n",
       "      <td>ouija house</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27670</th>\n",
       "      <td>the purge</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29467</th>\n",
       "      <td>monsterwolf</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>mars attacks!</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>the mark of zorro</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title      genre\n",
       "18149           geronimo    Western\n",
       "34982              a-x-l    Fantasy\n",
       "1177   conquest of space    Fantasy\n",
       "10371      white feather    Western\n",
       "29160         the signal    Fantasy\n",
       "...                  ...        ...\n",
       "35426        ouija house     Horror\n",
       "27670          the purge    Fantasy\n",
       "29467        monsterwolf     Horror\n",
       "9749       mars attacks!    Fantasy\n",
       "4115   the mark of zorro  Adventure\n",
       "\n",
       "[3249 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv\n",
    "df = df[df['country'] == 'United States'] #Country == United States\n",
    "df = df[df['genre'].isin(['Action','Horror','Fantasy','Western','Adventure'])] #Filter genre\n",
    "df = df[df['title'].str.len() < 21] # Title does not have more than 20 characters\n",
    "df['title'] = df['title'].apply(lambda s: s.lower()) #Set all titles to lowercase\n",
    "df = df[['title','genre']] # Only title and genre columns are needed\n",
    "\n",
    "\n",
    "df = df.sample(frac=1) #Shuffle dataset\n",
    "df.to_csv('filtered_data.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448acbaa",
   "metadata": {},
   "source": [
    "Split the filtered data into 80% train, 10% validation, and 10% test.\n",
    "You will only need the title and genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1fca47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:02.895489Z",
     "start_time": "2022-11-21T23:50:02.880493Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "#Train = 80%, Other = 20%\n",
    "train_x, other_x, train_y, other_y = sklearn.model_selection.train_test_split(df['title'],df['genre'],\n",
    "                                                             test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "#Split other in half -> [Train = 80%, Val = 10%, Test = 10%]\n",
    "val_x, test_x, val_y, test_y = sklearn.model_selection.train_test_split(other_x, other_y,\n",
    "                                                       test_size=0.5, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d5332",
   "metadata": {},
   "source": [
    "From your processed data set, display:\n",
    "\n",
    "* the amount of movies in each genre and split\n",
    "* 5 examples of movie titles from each genre and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e8adf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:50:02.911489Z",
     "start_time": "2022-11-21T23:50:02.896493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Movies in Training Set:\n",
      "Action       695\n",
      "Horror       655\n",
      "Fantasy      436\n",
      "Western      431\n",
      "Adventure    382\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Validation Set:\n",
      "Action       95\n",
      "Horror       87\n",
      "Western      55\n",
      "Fantasy      48\n",
      "Adventure    40\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Testing Set:\n",
      "Action       98\n",
      "Horror       76\n",
      "Fantasy      58\n",
      "Western      51\n",
      "Adventure    42\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Amount of Movies in Training Set:')\n",
    "print(train_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Validation Set:')\n",
    "print(val_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Testing Set:')\n",
    "print(test_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1240be",
   "metadata": {},
   "source": [
    "## Title classification (25%)\n",
    "\n",
    "Your first task is to prove that a neural network can identify the genre of a movie based on its title.\n",
    "\n",
    "You will note that many titles are just a single word or two words long so you need to work at the character level instead of the word level, that is, a token would be a single character, including punctuation marks and spaces.\n",
    "You must also lowercase the titles.\n",
    "Preprocess the data sets, create a neural network, and train it to classify the movie titles into their genre.\n",
    "Plot a graph of the **accuracy** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95ac75bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:59:49.124767Z",
     "start_time": "2022-11-21T23:59:48.558785Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenise each character.\n",
    "train_x = train_x.apply(lambda s: [*s])\n",
    "\n",
    "# Get the lengths of each title.\n",
    "text_lens = torch.tensor([len(sent) for sent in train_x],\n",
    "                         dtype=torch.int64, device=device)\n",
    "\n",
    "# Get the maximum lenght of a title.\n",
    "max_len = max(text_lens)\n",
    "\n",
    "# Create the vocabulary.\n",
    "vocab = ['<PAD>'] + sorted({token for sent in train_x for token in sent})\n",
    "\n",
    "# Pad the titles to max_len characters using <PAD> tokens.\n",
    "padded_train_x = [sent + ['<PAD>']*(max_len - len(sent)) for sent in train_x]\n",
    "\n",
    "# Replace each character with its index in the vocabulary.\n",
    "indexed_train_x = torch.tensor([[vocab.index(token) for token in title]\n",
    "                               for title in padded_train_x],\n",
    "                               dtype=torch.int64, device=device)\n",
    "\n",
    "# One Hot Encode Genres\n",
    "oneHotEncoder = sklearn.preprocessing.OneHotEncoder(\n",
    "    handle_unknown='ignore').fit(train_y.to_frame())\n",
    "one_train_y = torch.tensor(\n",
    "    oneHotEncoder.transform(train_y.to_frame()).toarray(),\n",
    "     dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# The target value for each character sequence\n",
    "seq_train_y = one_train_y.unsqueeze(1).tile(1,max_len,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66985d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T00:00:23.065663Z",
     "start_time": "2022-11-22T00:00:23.048661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2599, 20, 5])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_train_x.shape\n",
    "seq_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05bf0917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:59:25.045544Z",
     "start_time": "2022-11-21T23:59:25.031543Z"
    },
    "code_folding": [
     28
    ]
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding_matrix = torch.nn.Embedding(\n",
    "            vocab_size, embedding_size, device=device)\n",
    "\n",
    "        # Forward State\n",
    "        self.rnn_fw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_cell = torch.nn.LSTMCell(\n",
    "            embedding_size, hidden_size, device=device)\n",
    "\n",
    "        # Backward State\n",
    "        self.rnn_bw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_cell = torch.nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Input to this layer will be the concatanated fw and bw states\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            2*hidden_size, num_classes, device=device)\n",
    "\n",
    "    def forward(self, x, text_lens):\n",
    "        batch_size = x.shape[0]  # Number of titles\n",
    "        time_steps = x.shape[1]  # Number of characters\n",
    "\n",
    "        # Pass indices to embedding matrix\n",
    "        embedded = self.embedding_matrix(x)\n",
    "\n",
    "        # Get Forward State\n",
    "        state = self.rnn_fw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_fw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            (state, c) = self.rnn_fw_cell(embedded[:, t, :], (state, c))\n",
    "            interm_states.append(state)\n",
    "        interm_states_fw = torch.stack(interm_states, dim=1)\n",
    "\n",
    "        # Get Backward Intermediate States\n",
    "        state = self.rnn_bw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_bw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "\n",
    "        for t in reversed(range(time_steps)):\n",
    "            mask = (t < text_lens).unsqueeze(1).tile((1, self.hidden_size))\n",
    "            (next_state, next_c) = self.rnn_bw_cell(\n",
    "                embedded[:, t, :], (state, c))\n",
    "            \n",
    "            #Apply mask\n",
    "            state = torch.where(mask, next_state, state)\n",
    "            c = torch.where(mask, next_c,c)\n",
    "            \n",
    "            interm_states.append(state)\n",
    "            \n",
    "        interm_states_bw = torch.stack(\n",
    "            interm_states[::-1], dim=1)  # Re-Reverse states\n",
    "\n",
    "        # Concatanate forward and backward states\n",
    "        interm_states = torch.cat((interm_states_fw, interm_states_bw), dim=2)\n",
    "        \n",
    "        # Pass through output layer\n",
    "        return self.output_layer(interm_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76aa48a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:59:31.668042Z",
     "start_time": "2022-11-21T23:59:26.420087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n",
      "torch.Size([2599, 20, 5]) torch.Size([20, 2599, 5])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2599) to match target batch_size (20).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GABRIE~1\\AppData\\Local\\Temp/ipykernel_18228/3602554023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#Calculate Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     errors = torch.nn.functional.cross_entropy(\n\u001b[0m\u001b[0;32m     33\u001b[0m          output, seq_train_y, reduction='none')\n\u001b[0;32m     34\u001b[0m     \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3014\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (2599) to match target batch_size (20)."
     ]
    }
   ],
   "source": [
    "model = Model(len(vocab), embedding_size=2, hidden_size=2,\n",
    "              num_classes=len(train_y.unique()))\n",
    "model.to(device)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print('step', 'error')\n",
    "train_errors = []\n",
    "\n",
    "# Generate Mask\n",
    "batch_size = seq_train_y.shape[0]\n",
    "time_steps = seq_train_y.shape[1]\n",
    "mask = torch.zeros((batch_size, time_steps, 1),\n",
    "                   dtype=torch.bool, device=device)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    for j in range(time_steps):\n",
    "        if j >= text_lens[i]:\n",
    "            mask[i, j, :] = 1\n",
    "\n",
    "# Epoch Loop\n",
    "for step in range(1, 10_000+1):\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    #Get output\n",
    "    output = model(indexed_train_x, text_lens)\n",
    "    \n",
    "    print(output.shape,seq_train_y.shape)\n",
    "    \n",
    "    #Calculate Error\n",
    "    errors = torch.nn.functional.cross_entropy(\n",
    "         output, seq_train_y, reduction='none')\n",
    "    errors = torch.masked_fill(errors, mask, 0.0)\n",
    "    error = errors.sum()/text_lens.sum()\n",
    "    \n",
    "    #Record error\n",
    "    train_errors.append(error.detach().tolist())\n",
    "    \n",
    "    #Apply BackPropogation and HyperParameter Tuning\n",
    "    error.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(step, errors[-1])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('Title', 'Predicted Genre')\n",
    "    outputs = torch.sigmoid(model(indexed_train_x, text_lens))\n",
    "    for (sent, output) in zip(train_x, outputs):\n",
    "        print(''.join(sent), output)\n",
    "\n",
    "(fig, ax) = plt.subplots(1, 1)\n",
    "ax.set_xlabel('step')\n",
    "ax.set_ylabel('$E$')\n",
    "ax.plot(range(1, len(errors) + 1), errors,\n",
    "        color='blue', linestyle='-', linewidth=3)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b24aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:52:20.334127Z",
     "start_time": "2022-11-21T23:52:20.321104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2599, 20, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n",
    "seq_train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53265d7",
   "metadata": {},
   "source": [
    "Measure the F1 score performance of the model when applied on the test set.\n",
    "Also plot a confusion matrix showing how often each genre is mistaken as another genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c811f",
   "metadata": {},
   "source": [
    "## Title generation (25%)\n",
    "\n",
    "Now that you've proven that titles and genre are related, make a model that can generate a title given a genre.\n",
    "\n",
    "Again, you need to generate tokens at the character level instead of the word level and the titles must be lowercased.\n",
    "Preprocess the data sets, create a neural network, and train it to generate the movie titles given their genre.\n",
    "Plot a graph of the **perplexity** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89209908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da86299f",
   "metadata": {},
   "source": [
    "Generate 3 titles for every genre.\n",
    "Make sure that the titles are not all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97665b",
   "metadata": {},
   "source": [
    "## Language models as classifiers (30%)\n",
    "\n",
    "It occurs to you that the movie title generator can also be used as a classifier by doing the following:\n",
    "\n",
    "* Let title $t$ be the title that you want to classify.\n",
    "* For every genre $g$,\n",
    "    * Use the generator as a language model to get the probability of $t$ (the whole title) using genre $g$.\n",
    "* Pick the genre that makes the language model give the largest probability.\n",
    "\n",
    "The producer is thrilled to not need two separate models and now you have to implement this.\n",
    "**Use the preprocessed test set from the previous task** in order to find the genre that makes the language model give the largest probability.\n",
    "There is no need to plot anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3841496d",
   "metadata": {},
   "source": [
    "Just like in the classification task, measure the F1 score and plot the confusion matrix of this new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148060ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6399514",
   "metadata": {},
   "source": [
    "Write a paragraph or psuedo code to describe what your code above does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.092337Z",
     "start_time": "2022-11-21T16:55:57.092337Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5888e6",
   "metadata": {},
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "The producer's funders are asking for a report about this new technology they invested in.\n",
    "In 300 words, write your interpretation of the results together with what you think could make the model perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fa26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.093337Z",
     "start_time": "2022-11-21T16:55:57.093337Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
