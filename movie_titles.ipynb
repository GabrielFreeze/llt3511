{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd37655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:31.100327Z",
     "start_time": "2022-11-23T21:03:31.088326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-family: JetBrains Mono;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-family: JetBrains Mono;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c304f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:35.086387Z",
     "start_time": "2022-11-23T21:03:32.283326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suggested imports. Do not use import any modules that are not in the requirements.txt file on the VLE.\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98e8ff",
   "metadata": {},
   "source": [
    "# Movie titles assignment\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "* [Data filtering and splitting (10%)](#Data-filtering-and-splitting-(10%))\n",
    "* [Title classification (25%)](#Title-classification-(25%))\n",
    "* [Title generation (25%)](#Title-generation-(25%))\n",
    "* [Language models as classifiers (30%)](#Language-models-as-classifiers-(30%))\n",
    "* [Conclusion (10%)](#Conclusion-(10%))\n",
    "\n",
    "Information:\n",
    "\n",
    "This assignment is 100% of your assessment.\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5373",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "A big shot Hollywood producer is looking for a way to automatically generate new movie titles for future movies and you have been employed to do this (in exchange for millions of dollars!).\n",
    "A data set of movie details has already been collected from IMDb for you and your task is to create the model and the algorithms necessary to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2f45",
   "metadata": {},
   "source": [
    "## Data filtering and splitting (10%)\n",
    "\n",
    "Start by downloading the CSV file `filmtv_movies - ENG.csv` from [this kaggle data set](https://www.kaggle.com/datasets/stefanoleone992/filmtv-movies-dataset).\n",
    "\n",
    "The CSV file needs to be filtered as the producer is only interested in certain types of movie titles.\n",
    "Load the file and filter it so that only movies with the following criteria are kept:\n",
    "\n",
    "* The country needs to be `United States` (and no other country should be mentioned).\n",
    "* The genre should be `Action`, `Horror`, `Fantasy`, `Western`, and `Adventure`.\n",
    "* The title should not have more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751ea71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:38.722389Z",
     "start_time": "2022-11-23T21:03:38.375390Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2a2e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:40.839926Z",
     "start_time": "2022-11-23T21:03:40.452400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>empire strike back</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>fluke</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35540</th>\n",
       "      <td>ford v. ferrari</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30257</th>\n",
       "      <td>see no evil 2</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>armageddon</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>grizzly falls</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>blue heat</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>death race 2000</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>the hanging tree</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>from dusk till dawn</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title      genre\n",
       "15575   empire strike back  Adventure\n",
       "8524                 fluke  Adventure\n",
       "35540      ford v. ferrari     Action\n",
       "30257        see no evil 2     Horror\n",
       "11026           armageddon    Fantasy\n",
       "...                    ...        ...\n",
       "12035        grizzly falls  Adventure\n",
       "3653             blue heat     Action\n",
       "14339      death race 2000    Fantasy\n",
       "127       the hanging tree    Western\n",
       "9670   from dusk till dawn     Horror\n",
       "\n",
       "[3249 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv\n",
    "df = df[df['country'] == 'United States'] #Country == United States\n",
    "df = df[df['genre'].isin(['Action','Horror','Fantasy','Western','Adventure'])] #Filter genre\n",
    "df = df[df['title'].str.len() < 21] # Title does not have more than 20 characters\n",
    "df['title'] = df['title'].apply(lambda s: s.lower()) #Set all titles to lowercase\n",
    "df = df[['title','genre']] # Only title and genre columns are needed\n",
    "\n",
    "\n",
    "df = df.sample(frac=1) #Shuffle dataset\n",
    "df.to_csv('filtered_data.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448acbaa",
   "metadata": {},
   "source": [
    "Split the filtered data into 80% train, 10% validation, and 10% test.\n",
    "You will only need the title and genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1fca47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:42.344925Z",
     "start_time": "2022-11-23T21:03:42.331928Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "#Train = 80%, Other = 20%\n",
    "train_x, other_x, train_y, other_y = sklearn.model_selection.train_test_split(df['title'],df['genre'],\n",
    "                                                             test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "#Split other in half -> [Train = 80%, Val = 10%, Test = 10%]\n",
    "val_x, test_x, val_y, test_y = sklearn.model_selection.train_test_split(other_x, other_y,\n",
    "                                                       test_size=0.5, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d5332",
   "metadata": {},
   "source": [
    "From your processed data set, display:\n",
    "\n",
    "* the amount of movies in each genre and split\n",
    "* 5 examples of movie titles from each genre and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e8adf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:03:48.880941Z",
     "start_time": "2022-11-23T21:03:48.864940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Movies in Training Set:\n",
      "Action       708\n",
      "Horror       666\n",
      "Fantasy      434\n",
      "Western      424\n",
      "Adventure    367\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Validation Set:\n",
      "Action       89\n",
      "Horror       78\n",
      "Fantasy      58\n",
      "Adventure    53\n",
      "Western      47\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Testing Set:\n",
      "Action       91\n",
      "Horror       74\n",
      "Western      66\n",
      "Fantasy      50\n",
      "Adventure    44\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Amount of Movies in Training Set:')\n",
    "print(train_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Validation Set:')\n",
    "print(val_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Testing Set:')\n",
    "print(test_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1240be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Title classification (25%)\n",
    "\n",
    "Your first task is to prove that a neural network can identify the genre of a movie based on its title.\n",
    "\n",
    "You will note that many titles are just a single word or two words long so you need to work at the character level instead of the word level, that is, a token would be a single character, including punctuation marks and spaces.\n",
    "You must also lowercase the titles.\n",
    "Preprocess the data sets, create a neural network, and train it to classify the movie titles into their genre.\n",
    "Plot a graph of the **accuracy** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95ac75bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:54:41.488599Z",
     "start_time": "2022-11-23T21:54:40.673585Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenise each character.\n",
    "train_x = train_x.apply(lambda s: [*s])\n",
    "\n",
    "# Get the lengths of each title.\n",
    "text_lens = torch.tensor([len(sent) for sent in train_x],\n",
    "                         dtype=torch.int64, device=device)\n",
    "\n",
    "# Get the maximum lenght of a title.\n",
    "max_len = max(text_lens)\n",
    "\n",
    "# Create the vocabulary.\n",
    "vocab = ['<PAD>'] + sorted({token for sent in train_x for token in sent})\n",
    "\n",
    "# Pad the titles to max_len characters using <PAD> tokens.\n",
    "padded_train_x = [sent + ['<PAD>']*(max_len - len(sent)) for sent in train_x]\n",
    "\n",
    "# Replace each character with its index in the vocabulary.\n",
    "indexed_train_x = torch.tensor([[vocab.index(token) for token in title]\n",
    "                               for title in padded_train_x],\n",
    "                               dtype=torch.int64, device=device)\n",
    "\n",
    "###############FIX\n",
    "categories = ['Action', 'Horror', 'Fantasy', 'Western', 'Adventure']\n",
    "cat2idx = {cat: i for (i, cat) in enumerate(categories)}\n",
    "\n",
    "indexed_train_y = torch.tensor(train_y.map(cat2idx.get).to_numpy()[:, None],\n",
    "                           dtype=torch.int64, device=device)\n",
    "\n",
    "# The target value for each character sequence\n",
    "seq_train_y = indexed_train_y.tile(1, max_len)\n",
    "\n",
    "# Number of classes to classify\n",
    "# num_classes = seq_train_y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66985d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T22:27:49.073182Z",
     "start_time": "2022-11-23T22:27:49.054186Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [3, 3, 3,  ..., 3, 3, 3]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05bf0917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:55:05.937954Z",
     "start_time": "2022-11-23T21:55:05.915955Z"
    },
    "code_folding": [
     2,
     28
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding_matrix = torch.nn.Embedding(\n",
    "            vocab_size, embedding_size, device=device)\n",
    "\n",
    "        # Forward State\n",
    "        self.rnn_fw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_cell = torch.nn.LSTMCell(\n",
    "            embedding_size, hidden_size, device=device)\n",
    "\n",
    "        # Backward State\n",
    "        self.rnn_bw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_cell = torch.nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Input to this layer will be the concatanated fw and bw states\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            2*hidden_size, num_classes, device=device)\n",
    "\n",
    "    def forward(self, x, text_lens):\n",
    "        batch_size = x.shape[0]  # Number of titles\n",
    "        time_steps = x.shape[1]  # Number of characters\n",
    "\n",
    "        # Pass indices to embedding matrix\n",
    "        embedded = self.embedding_matrix(x)\n",
    "\n",
    "        # Get Forward State\n",
    "        state = self.rnn_fw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_fw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            (state, c) = self.rnn_fw_cell(embedded[:, t, :], (state, c))\n",
    "            interm_states.append(state)\n",
    "        interm_states_fw = torch.stack(interm_states, dim=1)\n",
    "\n",
    "        # Get Backward Intermediate States\n",
    "        state = self.rnn_bw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_bw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "\n",
    "        for t in reversed(range(time_steps)):\n",
    "            mask = (t < text_lens).unsqueeze(1).tile((1, self.hidden_size))\n",
    "            (next_state, next_c) = self.rnn_bw_cell(\n",
    "                embedded[:, t, :], (state, c))\n",
    "            \n",
    "            #Apply mask\n",
    "            state = torch.where(mask, next_state, state)\n",
    "            c = torch.where(mask, next_c,c)\n",
    "            \n",
    "            interm_states.append(state)\n",
    "            \n",
    "        interm_states_bw = torch.stack(\n",
    "            interm_states[::-1], dim=1)  # Re-Reverse states\n",
    "\n",
    "        # Concatanate forward and backward states\n",
    "        interm_states = torch.cat((interm_states_fw, interm_states_bw), dim=2)\n",
    "        \n",
    "        # Pass through output layer\n",
    "        return self.output_layer(interm_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4636f06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T21:36:52.244019Z",
     "start_time": "2022-11-23T21:36:52.226023Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2599, 20, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape\n",
    "# errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76aa48a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T22:26:02.465667Z",
     "start_time": "2022-11-23T22:14:46.796988Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n",
      "10000 1.5052309036254883\n",
      "20000 1.497367024421692\n",
      "30000 1.4906222820281982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GABRIE~1\\AppData\\Local\\Temp/ipykernel_8316/4104513071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#Get output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed_train_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_lens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#     print(f'Train X: {indexed_train_x.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\GABRIE~1\\AppData\\Local\\Temp/ipykernel_8316/1227938400.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, text_lens)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_fw_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0minterm_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0minterm_states_fw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterm_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[0;32m   1190\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(len(vocab), embedding_size=2, hidden_size=2,\n",
    "              num_classes=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print('step', 'error')\n",
    "train_errors = []\n",
    "\n",
    "# Generate Mask\n",
    "batch_size = seq_train_y.shape[0]\n",
    "time_steps = seq_train_y.shape[1]\n",
    "mask = torch.zeros((batch_size, time_steps),\n",
    "                   dtype=torch.bool, device=device)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    for j in range(time_steps):\n",
    "        if j >= text_lens[i]:\n",
    "            mask[i, j] = 1\n",
    "\n",
    "# Epoch Loop\n",
    "for step in range(1, 100_000+1):\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    #Get output\n",
    "    output = model(indexed_train_x, text_lens)\n",
    "    \n",
    "\n",
    "    #Calculate Error\n",
    "    errors = torch.nn.functional.cross_entropy(\n",
    "         output.transpose(1,2), seq_train_y, reduction='none')\n",
    "\n",
    "#     print(f'Train X: {indexed_train_x.shape}')\n",
    "#     print(f'Train Y: {seq_train_y.shape}')\n",
    "#     print(f'Output:  {output.shape}')    \n",
    "#     print(f'Errors:  {errors.shape}')\n",
    "#     print(f'Mask:    {mask.shape}')\n",
    "    \n",
    "    errors = torch.masked_fill(errors, mask, 0.0)\n",
    "    error = errors.sum()/text_lens.sum()\n",
    "    \n",
    "    #Record error\n",
    "    train_errors.append(error.detach().tolist())\n",
    "    \n",
    "    #Apply BackPropogation and HyperParameter Tuning\n",
    "    error.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    if step % 10_000 == 0:\n",
    "        print(step, train_errors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70635d74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-23T22:26:08.641735Z",
     "start_time": "2022-11-23T22:26:08.298735Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 31.58%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = torch.softmax(\n",
    "        model(indexed_train_x, text_lens), dim=2).cpu().numpy().argmax(axis=2)\n",
    "    num_correct = 0\n",
    "    for (true_tags, output_tags, text_len) in zip(seq_train_y.tolist(), outputs.tolist(), text_lens):\n",
    "        for j in range(text_len):\n",
    "            if true_tags[j] == output_tags[j]:\n",
    "                num_correct += 1\n",
    "    accuracy = num_correct/sum(text_lens)\n",
    "    print('accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b24aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T23:52:20.334127Z",
     "start_time": "2022-11-21T23:52:20.321104Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2599, 20, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n",
    "seq_train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53265d7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Measure the F1 score performance of the model when applied on the test set.\n",
    "Also plot a confusion matrix showing how often each genre is mistaken as another genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c811f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Title generation (25%)\n",
    "\n",
    "Now that you've proven that titles and genre are related, make a model that can generate a title given a genre.\n",
    "\n",
    "Again, you need to generate tokens at the character level instead of the word level and the titles must be lowercased.\n",
    "Preprocess the data sets, create a neural network, and train it to generate the movie titles given their genre.\n",
    "Plot a graph of the **perplexity** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89209908",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da86299f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Generate 3 titles for every genre.\n",
    "Make sure that the titles are not all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6465",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97665b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Language models as classifiers (30%)\n",
    "\n",
    "It occurs to you that the movie title generator can also be used as a classifier by doing the following:\n",
    "\n",
    "* Let title $t$ be the title that you want to classify.\n",
    "* For every genre $g$,\n",
    "    * Use the generator as a language model to get the probability of $t$ (the whole title) using genre $g$.\n",
    "* Pick the genre that makes the language model give the largest probability.\n",
    "\n",
    "The producer is thrilled to not need two separate models and now you have to implement this.\n",
    "**Use the preprocessed test set from the previous task** in order to find the genre that makes the language model give the largest probability.\n",
    "There is no need to plot anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8fd6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3841496d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just like in the classification task, measure the F1 score and plot the confusion matrix of this new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148060ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6399514",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write a paragraph or psuedo code to describe what your code above does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.092337Z",
     "start_time": "2022-11-21T16:55:57.092337Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5888e6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "The producer's funders are asking for a report about this new technology they invested in.\n",
    "In 300 words, write your interpretation of the results together with what you think could make the model perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fa26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.093337Z",
     "start_time": "2022-11-21T16:55:57.093337Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
