{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c304f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:17.056581Z",
     "start_time": "2022-11-21T18:04:15.244582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suggested imports. Do not use import any modules that are not in the requirements.txt file on the VLE.\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98e8ff",
   "metadata": {},
   "source": [
    "# Movie titles assignment\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "* [Data filtering and splitting (10%)](#Data-filtering-and-splitting-(10%))\n",
    "* [Title classification (25%)](#Title-classification-(25%))\n",
    "* [Title generation (25%)](#Title-generation-(25%))\n",
    "* [Language models as classifiers (30%)](#Language-models-as-classifiers-(30%))\n",
    "* [Conclusion (10%)](#Conclusion-(10%))\n",
    "\n",
    "Information:\n",
    "\n",
    "This assignment is 100% of your assessment.\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5373",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A big shot Hollywood producer is looking for a way to automatically generate new movie titles for future movies and you have been employed to do this (in exchange for millions of dollars!).\n",
    "A data set of movie details has already been collected from IMDb for you and your task is to create the model and the algorithms necessary to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2f45",
   "metadata": {},
   "source": [
    "## Data filtering and splitting (10%)\n",
    "\n",
    "Start by downloading the CSV file `filmtv_movies - ENG.csv` from [this kaggle data set](https://www.kaggle.com/datasets/stefanoleone992/filmtv-movies-dataset).\n",
    "\n",
    "The CSV file needs to be filtered as the producer is only interested in certain types of movie titles.\n",
    "Load the file and filter it so that only movies with the following criteria are kept:\n",
    "\n",
    "* The country needs to be `United States` (and no other country should be mentioned).\n",
    "* The genre should be `Action`, `Horror`, `Fantasy`, `Western`, and `Adventure`.\n",
    "* The title should not have more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751ea71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:17.430579Z",
     "start_time": "2022-11-21T18:04:17.057582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Animation', 'Drama', 'Romantic', 'Comedy', 'Crime', 'Thriller',\n",
       "       'Adventure', 'Documentary', 'Horror', 'Action', 'Western', 'Spy',\n",
       "       'Biography', 'Musical', 'Fantasy', 'War', 'Grotesque', 'Gangster',\n",
       "       'Mélo', 'Mythology', 'History', 'Noir', 'Super-hero', 'Biblical',\n",
       "       'Sport', 'Sperimental', nan, 'Short Movie'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv\n",
    "df['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2a2e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:17.854579Z",
     "start_time": "2022-11-21T18:04:17.431584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>the three outlaws</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10209</th>\n",
       "      <td>the lost world</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11719</th>\n",
       "      <td>progeny</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>invaders from mars</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21960</th>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>forever amber</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31728</th>\n",
       "      <td>arrival</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>hawaii</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12132</th>\n",
       "      <td>rush hour</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31826</th>\n",
       "      <td>dog eat dog</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title      genre\n",
       "19321   the three outlaws    Western\n",
       "10209      the lost world  Adventure\n",
       "11719             progeny     Horror\n",
       "9101   invaders from mars    Fantasy\n",
       "21960     friday the 13th     Horror\n",
       "...                   ...        ...\n",
       "202         forever amber  Adventure\n",
       "31728             arrival    Fantasy\n",
       "6900               hawaii  Adventure\n",
       "12132           rush hour     Action\n",
       "31826         dog eat dog     Action\n",
       "\n",
       "[3249 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')  #Load full csv\n",
    "df = df[df['country'] == 'United States'] #Country == United States\n",
    "df = df[df['genre'].isin(['Action','Horror','Fantasy','Western','Adventure'])] #Filter genre\n",
    "df = df[df['title'].str.len() < 21] # Title does not have more than 20 characters\n",
    "df['title'] = df['title'].apply(lambda s: s.lower()) #Set all titles to lowercase\n",
    "df = df[['title','genre']] # Only title and genre columns are needed\n",
    "\n",
    "\n",
    "df = df.sample(frac=1) #Shuffle dataset\n",
    "df.to_csv('filtered_data.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448acbaa",
   "metadata": {},
   "source": [
    "Split the filtered data into 80% train, 10% validation, and 10% test.\n",
    "You will only need the title and genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1fca47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:17.869580Z",
     "start_time": "2022-11-21T18:04:17.856580Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "#Train = 80%, Other = 20%\n",
    "train_x, other_x, train_y, other_y = sklearn.model_selection.train_test_split(df['title'],df['genre'],\n",
    "                                                             test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "#Split other in half -> [Train = 80%, Val = 10%, Test = 10%]\n",
    "val_x, test_x, val_y, test_y = sklearn.model_selection.train_test_split(other_x, other_y,\n",
    "                                                       test_size=0.5, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d5332",
   "metadata": {},
   "source": [
    "From your processed data set, display:\n",
    "\n",
    "* the amount of movies in each genre and split\n",
    "* 5 examples of movie titles from each genre and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e8adf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:17.884581Z",
     "start_time": "2022-11-21T18:04:17.870582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Movies in Training Set:\n",
      "Action       697\n",
      "Horror       652\n",
      "Western      443\n",
      "Fantasy      425\n",
      "Adventure    382\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Validation Set:\n",
      "Action       102\n",
      "Horror        81\n",
      "Fantasy       56\n",
      "Western       47\n",
      "Adventure     39\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "Amount of Movies in Testing Set:\n",
      "Action       89\n",
      "Horror       85\n",
      "Fantasy      61\n",
      "Western      47\n",
      "Adventure    43\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Amount of Movies in Training Set:')\n",
    "print(train_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Validation Set:')\n",
    "print(val_y.value_counts())\n",
    "\n",
    "print('\\nAmount of Movies in Testing Set:')\n",
    "print(test_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1240be",
   "metadata": {},
   "source": [
    "## Title classification (25%)\n",
    "\n",
    "Your first task is to prove that a neural network can identify the genre of a movie based on its title.\n",
    "\n",
    "You will note that many titles are just a single word or two words long so you need to work at the character level instead of the word level, that is, a token would be a single character, including punctuation marks and spaces.\n",
    "You must also lowercase the titles.\n",
    "Preprocess the data sets, create a neural network, and train it to classify the movie titles into their genre.\n",
    "Plot a graph of the **accuracy** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ac75bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:04:19.322582Z",
     "start_time": "2022-11-21T18:04:17.885581Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenise each character.\n",
    "train_x = train_x.apply(lambda s: [*s])\n",
    "\n",
    "# Get the lengths of each title.\n",
    "text_lens = torch.tensor([len(sent) for sent in train_x],\n",
    "                         dtype=torch.int64, device=device)\n",
    "\n",
    "# Get the maximum lenght of a title.\n",
    "max_len = max(text_lens)\n",
    "\n",
    "# Create the vocabulary.\n",
    "vocab = ['<PAD>'] + sorted({token for sent in train_x for token in sent})\n",
    "\n",
    "# Pad the titles to max_len characters using <PAD> tokens.\n",
    "padded_train_x = [sent + ['<PAD>']*(max_len - len(sent)) for sent in train_x]\n",
    "\n",
    "# Replace each character with its index in the vocabulary.\n",
    "indexed_train_x = torch.tensor([[vocab.index(token) for token in title]\n",
    "                               for title in padded_train_x],\n",
    "                               dtype=torch.int64, device=device)\n",
    "\n",
    "# Label Encode Genres\n",
    "labelEncoder = sklearn.preprocessing.LabelEncoder().fit(train_y)\n",
    "\n",
    "encoded_train_y = torch.tensor(\n",
    "    labelEncoder.transform(train_y),\n",
    "    dtype=torch.int64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bf0917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T18:14:51.730660Z",
     "start_time": "2022-11-21T18:14:51.716659Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding_matrix = torch.nn.Embedding(\n",
    "            vocab_size, embedding_size, device=device)\n",
    "\n",
    "        # Forward State\n",
    "        self.rnn_fw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_fw_cell = torch.nn.LSTMCell(\n",
    "            embedding_size, hidden_size, device=device)\n",
    "\n",
    "        # Backward State\n",
    "        self.rnn_bw_s0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_c0 = torch.nn.Parameter(torch.zeros(\n",
    "            (hidden_size,), dtype=torch.float32, device=device))\n",
    "        self.rnn_bw_cell = torch.nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Input to this layer will be the concatanated fw and bw states\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            2*hidden_size, num_classes, device=device)\n",
    "\n",
    "    def forward(self, x, text_lens):\n",
    "        batch_size = x.shape[0]  # Number of titles\n",
    "        time_steps = x.shape[1]  # Number of characters\n",
    "\n",
    "        # Pass indices to embedding matrix\n",
    "        embedded = self.embedding_matrix(x)\n",
    "\n",
    "        #Get Forward State\n",
    "        state = self.rnn_fw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_fw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            (state, c) = self.rnn_fw_cell(embedded[:, t, :], (state, c))\n",
    "            interm_states.append(state)\n",
    "        interm_states_fw = torch.stack(interm_states, dim=1)\n",
    "        \n",
    "        #Get Backward Intermediate States\n",
    "        state = self.rnn_bw_s0.unsqueeze(0).tile((batch_size, 1))\n",
    "        c = self.rnn_bw_c0.unsqueeze(0).tile((batch_size, 1))\n",
    "        interm_states = []\n",
    "        \n",
    "        for t in reversed(range(time_steps)):\n",
    "            mask = (t < text_lens).unsqueeze(1).tile((1, self.hidden_size))\n",
    "            (next_state, next_c) = self.rnn_bw_cell(embedded[:, t, :], (state, c))\n",
    "            state = torch.where(mask, next_c, c)\n",
    "            interm_states.append(state)\n",
    "        interm_states_bw = torch.stack(interm_states[::-1], dim=1) #Re-Reverse states\n",
    "        \n",
    "        #Concatanate forward and backward states\n",
    "        interm_states = torch.cat((interm_states_fw, interm_states_bw), dim=2)\n",
    "        \n",
    "        #Pass through output layer\n",
    "        return self.output_layer(interm_states)  #TODO: Pass only last state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76aa48a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T17:33:54.647483Z",
     "start_time": "2022-11-21T17:32:11.714516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n",
      "500 1.5746501684188843\n",
      "1000 1.5547722578048706\n",
      "1500 1.5032740831375122\n",
      "2000 1.480414628982544\n",
      "2500 1.4726635217666626\n",
      "3000 1.4675484895706177\n",
      "3500 1.4647356271743774\n",
      "4000 1.462796926498413\n",
      "4500 1.4614856243133545\n",
      "5000 1.459925889968872\n",
      "5500 1.45846688747406\n",
      "6000 1.4570372104644775\n",
      "6500 1.456042766571045\n",
      "7000 1.4553512334823608\n",
      "7500 1.4548776149749756\n",
      "8000 1.4545657634735107\n",
      "8500 1.454073429107666\n",
      "9000 1.4535636901855469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GABRIE~1\\AppData\\Local\\Temp/ipykernel_21684/3396447851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         output, encoded_train_y)\n\u001b[0;32m     14\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(len(vocab), embedding_size=2, hidden_size=3,\n",
    "              num_classes=len(train_y.unique()))\n",
    "model.to(device)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print('step', 'error')\n",
    "errors = []\n",
    "for step in range(1, 10_000+1):\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    output = model(indexed_train_x, text_lens)\n",
    "    error = torch.nn.functional.cross_entropy(\n",
    "        output, encoded_train_y)\n",
    "    errors.append(error.detach().tolist())\n",
    "    error.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(step, errors[-1])\n",
    "print()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('sent', 'prediction')\n",
    "    outputs = torch.sigmoid(model(indexed_train_x, text_lens))\n",
    "    for (sent, output) in zip(train_x, outputs):\n",
    "        print(''.join(sent), output)\n",
    "\n",
    "(fig, ax) = plt.subplots(1, 1)\n",
    "ax.set_xlabel('step')\n",
    "ax.set_ylabel('$E$')\n",
    "ax.plot(range(1, len(errors) + 1), errors,\n",
    "        color='blue', linestyle='-', linewidth=3)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53265d7",
   "metadata": {},
   "source": [
    "Measure the F1 score performance of the model when applied on the test set.\n",
    "Also plot a confusion matrix showing how often each genre is mistaken as another genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c811f",
   "metadata": {},
   "source": [
    "## Title generation (25%) TODO: CHOOSE ARCHITECTURE\n",
    "\n",
    "Now that you've proven that titles and genre are related, make a model that can generate a title given a genre.\n",
    "\n",
    "Again, you need to generate tokens at the character level instead of the word level and the titles must be lowercased.\n",
    "Preprocess the data sets, create a neural network, and train it to generate the movie titles given their genre.\n",
    "Plot a graph of the **perplexity** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89209908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da86299f",
   "metadata": {},
   "source": [
    "Generate 3 titles for every genre.\n",
    "Make sure that the titles are not all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97665b",
   "metadata": {},
   "source": [
    "## Language models as classifiers (30%)\n",
    "\n",
    "It occurs to you that the movie title generator can also be used as a classifier by doing the following:\n",
    "\n",
    "* Let title $t$ be the title that you want to classify.\n",
    "* For every genre $g$,\n",
    "    * Use the generator as a language model to get the probability of $t$ (the whole title) using genre $g$.\n",
    "* Pick the genre that makes the language model give the largest probability.\n",
    "\n",
    "The producer is thrilled to not need two separate models and now you have to implement this.\n",
    "**Use the preprocessed test set from the previous task** in order to find the genre that makes the language model give the largest probability.\n",
    "There is no need to plot anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3841496d",
   "metadata": {},
   "source": [
    "Just like in the classification task, measure the F1 score and plot the confusion matrix of this new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148060ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6399514",
   "metadata": {},
   "source": [
    "Write a paragraph or psuedo code to describe what your code above does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.092337Z",
     "start_time": "2022-11-21T16:55:57.092337Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5888e6",
   "metadata": {},
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "The producer's funders are asking for a report about this new technology they invested in.\n",
    "In 300 words, write your interpretation of the results together with what you think could make the model perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fa26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T16:55:57.093337Z",
     "start_time": "2022-11-21T16:55:57.093337Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
